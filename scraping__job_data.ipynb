{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping _job_data.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CjwOiJ8p52pu",
        "ZGVxFeMD5-C_",
        "3uXDoitJ6E7y",
        "yP4ZmXxg78di",
        "ZuttFqBi6YFo",
        "zwnZl3gg6nYq",
        "FS1sv2lS9IGl"
      ],
      "authorship_tag": "ABX9TyPoO8+B+WJH3swpK3SvFBBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMAYadav/PROJECTS-/blob/main/scraping__job_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# URLS\n"
      ],
      "metadata": {
        "id": "CjwOiJ8p52pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LINKEDIN ='https://www.linkedin.com/jobs/quantitative-analyst-jobs/?originalSubdomain=in'\n",
        "#NAUKRI.COM = 'https://www.naukri.com/quant-analyst-jobs?cityTypeGid=6&cityTypeGid=51&cityTypeGid=72&cityTypeGid=73&cityTypeGid=97&cityTypeGid=134&cityTypeGid=135&cityTypeGid=138&cityTypeGid=139&cityTypeGid=183&cityTypeGid=213&cityTypeGid=220&cityTypeGid=350&cityTypeGid=9508&cityTypeGid=9509&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15'\n",
        "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36','referer':'https://linkedin.com','accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8','accept-encoding': 'gzip, deflate, br','accept-language': 'en-US,en;q=0.8','cache-control': 'no-cache','pragma': 'no-cache','upgrade-insecure-requests': '1',}\n",
        "source=requests.get('https://www.naukri.com/quant-analyst-jobs?cityTypeGid=6&cityTypeGid=51&cityTypeGid=72&cityTypeGid=73&cityTypeGid=97&cityTypeGid=134&cityTypeGid=135&cityTypeGid=138&cityTypeGid=139&cityTypeGid=183&cityTypeGid=213&cityTypeGid=220&cityTypeGid=350&cityTypeGid=9508&cityTypeGid=9509&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15',headers=headers)\n",
        "source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXZqaNnV58Ns",
        "outputId": "345deb88-0770-4e40-f1c1-02fde0357bb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Installations\n"
      ],
      "metadata": {
        "id": "ZGVxFeMD5-C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##installing selenium\n",
        "\n",
        "!pip install selenium bs4\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdHAbOT66j-Y",
        "outputId": "68654188-76fe-479d-acdb-15022780114f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (36.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (97.0.4692.71-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library Imports"
      ],
      "metadata": {
        "id": "3uXDoitJ6E7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##uploading liabraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive._mount('/content/drive')"
      ],
      "metadata": {
        "id": "cXhRtxd56lLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INITATING DRIVERS"
      ],
      "metadata": {
        "id": "yP4ZmXxg78di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##initate the selenium driver\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# options = Options()\n",
        "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Safari/537.36'\n",
        "options.add_argument('user-agent={0}'.format(user_agent))\n",
        "driver = webdriver.Chrome('chromedriver',options=options)"
      ],
      "metadata": {
        "id": "iK2ky5nX8Bj6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOUP OBJECT OF WEB PAGES"
      ],
      "metadata": {
        "id": "ZuttFqBi6YFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating pages for the scraping\n",
        "naukrilink=[]  ##creatng lists of the links on the page\n",
        "for i in range(1,500):\n",
        "  resources='https://www.naukri.com/quant-analyst-jobs-{}?cityTypeGid=6&cityTypeGid=51&cityTypeGid=72&cityTypeGid=73&cityTypeGid=97&cityTypeGid=134&cityTypeGid=135&cityTypeGid=138&cityTypeGid=139&cityTypeGid=183&cityTypeGid=213&cityTypeGid=220&cityTypeGid=350&cityTypeGid=9508&cityTypeGid=9509&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15'.format(i)\n",
        "  naukrilink.append(resources) \n",
        "  for j in naukrilink:\n",
        "    driver.get(j)\n",
        "    soup=BeautifulSoup(driver.page_source,'lxml') "
      ],
      "metadata": {
        "id": "fL9bqISO6z5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCRAPING/PARSING DATA"
      ],
      "metadata": {
        "id": "zwnZl3gg6nYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Company_website=[]\n",
        "Company_Name=[]\n",
        "Job_title=[]\n",
        "Experience=[]\n",
        "Salary=[]\n",
        "Location=[]\n",
        "Days_ago=[]\n",
        "Skills=[]\n",
        "skill=[]\n",
        "\n",
        "sourcefile=soup.find_all('article',{'class':'jobTuple bgWhite br4 mb-8'})\n",
        "\n",
        "for a in sourcefile:\n",
        "  Company_website.append(a.find('a',class_='title fw500 ellipsis').get('href'))  ## company website on naukri.com site\n",
        "  Company_Name.append(a.find('a',class_=\"subTitle ellipsis fleft\").text )  #company name\n",
        "  Job_title.append(a.find('a', class_=\"title fw500 ellipsis\").text)  ## Job title \n",
        "  Experience.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi experience\").text)  ##exprience asked by the company  for the job\n",
        "  Salary.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi salary\").text)    ##salary offered by the company  for the job\n",
        "  # a.find('span',class_=\"ellipsis fleft fs12 lh16 \").text  ## experience\n",
        "  Location.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi location\").text ) ## location of the job\n",
        "  Days_ago.append(a.find('span',class_=\"fleft fw500\").text)  ##no of days job posted ago\n",
        "  for li in a.find('ul',class_=\"tags has-description\").find_all('li'):    ##skills asked by the company\n",
        "    Skills.append(li.text)\n",
        "    skill.append(Skills)\n",
        "\n",
        "\n",
        "df=pd.DataFrame({'Company_website':Company_website,'Company_Name':Company_Name,'Job_title':Job_title,'Experience':Experience,'Salary':Salary,'Location':Location,'Days_ago':Days_ago,'Skills':skill},columns=['Company_website','Company_Name','Job_title','Experience','Salary','Location','Days_ago','Skills'])\n",
        "# df.append({'Company_website':Company_website,'Company_Name':Company_Name,'Job_title':Job_title,'Experience':Experience,'Salary':Salary,'Location':Location,'Days_ago':Days_ago},ignore_index = True)\n",
        "# df[ignore_index = True]\n",
        "# df.reset_index(drop=True, inplace=True)\n",
        "df.to_csv('naukri.com_job_dataset.csv',index=False)\n",
        "files.download('naukri.com_job_dataset.csv')\n"
      ],
      "metadata": {
        "id": "5ovmOQz_5-2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cSCXQ40s5-5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BACKGROUND WORK"
      ],
      "metadata": {
        "id": "FS1sv2lS9IGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install selenium bs4\n",
        "\n",
        "# !apt-get update\n",
        "\n",
        "# !apt install chromium-chromedriver\n",
        "\n",
        "\n",
        "# from selenium import webdriver\n",
        "# from selenium.webdriver.common.by import By\n",
        "# from bs4 import BeautifulSoup\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# import sys\n",
        "# sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "# options = webdriver.ChromeOptions()\n",
        "# options.add_argument('--headless')\n",
        "# options.add_argument('--no-sandbox')\n",
        "# options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# # options = Options()\n",
        "# user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Safari/537.36'\n",
        "# options.add_argument('user-agent={0}'.format(user_agent))\n",
        "\n",
        "\n",
        "\n",
        "# driver = webdriver.Chrome('chromedriver',options=options)\n",
        "# # for single linktesting purposes\n",
        "# # driver.get('https://www.naukri.com/quant-analyst-jobs?cityTypeGid=6&cityTypeGid=51&cityTypeGid=72&cityTypeGid=73&cityTypeGid=97&cityTypeGid=134&cityTypeGid=135&cityTypeGid=138&cityTypeGid=139&cityTypeGid=183&cityTypeGid=213&cityTypeGid=220&cityTypeGid=350&cityTypeGid=9508&cityTypeGid=9509&ctcFilter=0to3&ctcFilter=3to6&ctcFilter=6to10&ctcFilter=10to15')\n",
        "# # print(driver.page_source)\n"
      ],
      "metadata": {
        "id": "r61Ehhb5lr6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soup=BeautifulSoup(driver.page_source,'lxml')\n",
        "\n",
        "# # 4774*20\n"
      ],
      "metadata": {
        "id": "ECHzRoOKlsB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Company_website=[]\n",
        "# Company_Name=[]\n",
        "# Job_title=[]\n",
        "# Experience=[]\n",
        "# Salary=[]\n",
        "# Location=[]\n",
        "# Days_ago=[]\n",
        "# Skills=[]\n",
        "# skill=[]\n",
        "\n",
        "# sourcefile=soup.find_all('article',{'class':'jobTuple bgWhite br4 mb-8'})\n",
        "\n",
        "# for a in sourcefile:\n",
        "#   Company_website.append(a.find('a',class_='title fw500 ellipsis').get('href'))  ## company website on naukri.com site\n",
        "#   Company_Name.append(a.find('a',class_=\"subTitle ellipsis fleft\").text )  #company name\n",
        "#   Job_title.append(a.find('a', class_=\"title fw500 ellipsis\").text)  ## Job title \n",
        "#   Experience.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi experience\").text)  ##exprience asked by the company  for the job\n",
        "#   Salary.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi salary\").text)    ##salary offered by the company  for the job\n",
        "#   # a.find('span',class_=\"ellipsis fleft fs12 lh16 \").text  ## experience\n",
        "#   Location.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi location\").text ) ## location of the job\n",
        "#   Days_ago.append(a.find('span',class_=\"fleft fw500\").text)  ##no of days job posted ago\n",
        "#   for li in a.find('ul',class_=\"tags has-description\").find_all('li'):    ##skills asked by the company\n",
        "#     Skills.append(li.text)\n",
        "#     skill.append(Skills)\n",
        "\n",
        "\n",
        "# df=pd.DataFrame({'Company_website':Company_website,'Company_Name':Company_Name,'Job_title':Job_title,'Experience':Experience,'Salary':Salary,'Location':Location,'Days_ago':Days_ago,'Skills':skill},columns=['Company_website','Company_Name','Job_title','Experience','Salary','Location','Days_ago','Skills'])\n",
        "# # df.append({'Company_website':Company_website,'Company_Name':Company_Name,'Job_title':Job_title,'Experience':Experience,'Salary':Salary,'Location':Location,'Days_ago':Days_ago},ignore_index = True)\n",
        "# # df[ignore_index = True]\n",
        "# # df.reset_index(drop=True, inplace=True)\n",
        "# df.to_csv('naukri.com_job_dataset.csv',index=False)\n",
        "# files.download('naukri.com_job_dataset.csv')\n"
      ],
      "metadata": {
        "id": "aup8ofb62hBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # element of single container\n",
        "\n",
        "# # A=soup.find_all('article',{'class':'jobTuple bgWhite br4 mb-8'})\n",
        "\n",
        "# # comapny page on naukri.com for eliboratedexpilnations\n",
        "# A[0].find('a',class_='title fw500 ellipsis').get('href')\n",
        "# # results = soup.find(class_='list')\n",
        "# # job_elems = results.find_all('article',class_='jobTuple bgWhite br4 mb-8')\n",
        "\n",
        "# # job_elems \n",
        "\n",
        "# len(A)\n",
        "\n",
        "\n",
        "# colab=[]\n",
        "# for a in A :\n",
        "#   # print(a)\n",
        "#   colab.append(a.find('a',class_='title fw500 ellipsis').get('href'))\n",
        "\n",
        "# colab\n",
        "\n",
        "\n",
        "\n",
        "# # print(A[0])\n",
        "\n",
        "# # df = pd.DataFrame(columns=['Company_website','Company_Name','Job_title','Experience','Salary','Location','Days_ago'])\n",
        "\n",
        "\n",
        "\n",
        "# Company_website=[]\n",
        "# Company_Name=[]\n",
        "# Job_title=[]\n",
        "# Experience=[]\n",
        "# Salary=[]\n",
        "# Location=[]\n",
        "# Days_ago=[]\n",
        "# Skills=[]\n",
        "# for a in A:\n",
        "#   Company_website.append(a.find('a',class_='title fw500 ellipsis').get('href'))  ## company website on naukri.com site\n",
        "#   Company_Name.append(a.find('a',class_=\"subTitle ellipsis fleft\").text )  #company name\n",
        "#   Job_title.append(a.find('a', class_=\"title fw500 ellipsis\").text)  ## Job title \n",
        "#   Experience.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi experience\").text)  ##exprience asked by the company  for the job\n",
        "#   Salary.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi salary\").text)    ##salary offered by the company  for the job\n",
        "#   # a.find('span',class_=\"ellipsis fleft fs12 lh16 \").text  ## experience\n",
        "#   Location.append(a.find('li',class_=\"fleft grey-text br2 placeHolderLi location\").text ) ## location of the job\n",
        "#   Days_ago.append(a.find('span',class_=\"fleft fw500\").text)  ##no of days job posted ago\n",
        "#   # for li in a.find('ul',class_=\"tags has-description\").find_all('li'):    ##skills asked by the company\n",
        "#   #   Skills.append(li.text)\n",
        "\n",
        "\n",
        "# df=pd.DataFrame({'Company_website':Company_website,'Company_Name':Company_Name,'Job_title':Job_title,'Experience':Experience,'Salary':Salary,'Location':Location,'Days_ago':Days_ago},columns=['Company_website','Company_Name','Job_title','Experience','Salary','Location','Days_ago'])\n",
        "# # df.append({'Company_website':Company_website,'Company_Name':Company_Name,'Job_title':Job_title,'Experience':Experience,'Salary':Salary,'Location':Location,'Days_ago':Days_ago},ignore_index = True)\n",
        "# # df[ignore_index = True]\n",
        "# df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "71pKRPdgsFie"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1qvoCeTwvr3K"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}